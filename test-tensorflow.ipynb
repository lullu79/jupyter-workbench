{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee6009f-4065-40ae-829b-31ac5c8ec8f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 02:31:50.162887: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-02 02:31:51.611462: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2024-05-02 02:31:51.611674: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2024-05-02 02:31:51.611688: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7094659e-2921-47ee-82d4-9c3460abc92c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c33cf775-b7db-4444-9d0a-667b66f75b7b",
   "metadata": {},
   "source": [
    "TensorFlow를 사용하여 간단한 신경망을 구축하는 예제 코드를 제공해 드릴게요. \n",
    "여기서는 TensorFlow 2.x 버전을 기준으로, 기본적인 분류 문제를 해결하는 모델을 만드는 방법을 설명합니다. 이 예제에서는 패션 MNIST 데이터셋을 사용해 옷의 종류를 분류하는 모델을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50a43538-f206-47cc-b6a9-a53eedc3d9a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 02:39:29.220389: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2024-05-02 02:39:29.221362: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-05-02 02:39:29.221450: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-20240502-082715): /proc/driver/nvidia/version does not exist\n",
      "2024-05-02 02:39:29.223784: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4984 - accuracy: 0.8251\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3754 - accuracy: 0.8647\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3393 - accuracy: 0.8765\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3126 - accuracy: 0.8857\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2972 - accuracy: 0.8910\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2805 - accuracy: 0.8959\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2696 - accuracy: 0.9004\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2586 - accuracy: 0.9034\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2482 - accuracy: 0.9069\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2389 - accuracy: 0.9109\n",
      "313/313 - 1s - loss: 0.3435 - accuracy: 0.8828 - 621ms/epoch - 2ms/step\n",
      "\n",
      "Test accuracy: 0.8827999830245972\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# 데이터셋 로드\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# 데이터 정규화\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# 모델 구성\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),  # 입력 데이터를 1D 배열로 변환\n",
    "    Dense(128, activation='relu'),  # 128개의 뉴런을 가진 Dense 층\n",
    "    Dense(10, activation='softmax') # 10개 클래스에 대한 확률을 출력하는 softmax 층\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233fda67-2a0e-42b1-969d-66fc4656b924",
   "metadata": {},
   "source": [
    "이 코드는 다음과 같은 주요 단계를 포함합니다:\n",
    "\n",
    "데이터 로드 및 정규화: 패션 MNIST 데이터를 로드하고, 0과 1 사이의 값으로 정규화합니다.\n",
    "모델 구성: Sequential 모델을 사용하여 간단한 신경망을 구성합니다. 이 신경망은 입력층, 하나의 은닉층, 그리고 출력층으로 구성됩니다.\n",
    "모델 컴파일: 모델을 컴파일할 때, 손실 함수와 최적화 알고리즘을 지정합니다.\n",
    "모델 학습: fit 함수를 사용하여 모델을 학습시킵니다.\n",
    "모델 평가: evaluate 함수를 사용하여 테스트 데이터셋을 통해 모델을 평가합니다.\n",
    "이 코드를 실행하면 TensorFlow를 사용하여 기본적인 이미지 분류 모델을 어떻게 만드는지 이해할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a479397-5799-4bba-a4a1-a29165e335a7",
   "metadata": {},
   "source": [
    "이번에는 단일 뉴런을 사용하는 매우 간단한 선형 회귀 모델을 구축하는 예제를 보여 드릴게요. 이 예제는 입력 \n",
    "x\n",
    "x에 대해 \n",
    "y\n",
    "=\n",
    "3\n",
    "x\n",
    "+\n",
    "1\n",
    "y=3x+1과 같은 관계를 학습합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c1955dc-b609-4866-a536-8e2ecf2c7063",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 37.5516\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 26.0613\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.0884\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.5561\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.7174\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.0537\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2055\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.9230\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0330\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4155\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9870\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6896\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4832\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3400\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2406\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1716\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1237\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0904\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0673\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0512\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0400\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0323\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0268\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0230\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0204\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0185\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0172\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0156\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0151\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0147\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0144\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0142\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0140\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0139\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0137\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0136\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0135\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0134\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0133\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0132\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0132\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0131\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0130\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0129\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0128\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0128\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0127\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0126\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0125\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "예측값: X=10일 때 Y= [[31.653599]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 준비\n",
    "x = np.array([1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "y = np.array([4.0, 7.0, 10.0, 13.0], dtype=float)\n",
    "\n",
    "# 모델 생성\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, input_shape=[1])\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(x, y, epochs=50)\n",
    "\n",
    "# 예측\n",
    "print(\"예측값: X=10일 때 Y=\", model.predict([10.0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca858282-dfb7-4401-be4d-95e04789724d",
   "metadata": {},
   "source": [
    "이 코드에서는 다음과 같은 단계를 진행합니다:\n",
    "\n",
    "데이터 준비: 간단한 선형 관계를 가지는 소규모 데이터셋을 준비합니다.\n",
    "모델 생성: 하나의 유닛을 가진 Dense 층으로 구성된 매우 간단한 모델을 만듭니다. 이 유닛은 입력 \n",
    "x\n",
    "x를 받아 가중치와 편향을 사용하여 출력 \n",
    "y\n",
    "y를 계산합니다.\n",
    "모델 컴파일: 손실 함수로 평균 제곱 오차를 사용하고, 최적화 알고리즘으로 확률적 경사 하강법(SGD)을 사용합니다.\n",
    "모델 학습: 데이터를 모델에 입력하여 50번의 에포크 동안 학습시킵니다.\n",
    "예측: 학습된 모델을 사용하여 새로운 입력 \n",
    "x\n",
    "=\n",
    "10\n",
    "x=10에 대한 \n",
    "y\n",
    "y의 값을 예측합니다."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
